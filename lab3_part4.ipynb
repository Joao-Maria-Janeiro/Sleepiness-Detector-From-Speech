{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import argparse\n",
    "from itertools import count\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for the Development Dataset\n",
      "Results for prediction 1\n",
      "(0.5025163834053261, 0.5027017395157096, 0.4974962945849505, None)\n",
      "Results for tprediction 2\n",
      "(0.5206951528626322, 0.5160033518907361, 0.5074969553907376, None)\n",
      "Results for tprediction 3\n",
      "(0.5024612693653173, 0.5026090327676216, 0.5000593202596134, None)\n",
      "Results for majority vote\n",
      "(0.4953513956046768, 0.4956247230837395, 0.4944605367399485, None)\n"
     ]
    }
   ],
   "source": [
    "# Load Label\n",
    "devel_label_file = \"../lab3_part1/corpus/labels/dev_labels.csv\"\n",
    "labels_devel = pd.read_csv(devel_label_file, sep=',')\n",
    "\n",
    "# prediction files -> EDIT THESE PATHS TO YOUR PREDICTIONS\n",
    "dev_1_pred = 'is11_dev_result_svm.csv'\n",
    "test_1_pred = 'is11_test_result_svm.csv'\n",
    "\n",
    "dev_2_pred = 'is11_dev_result_nn.csv'\n",
    "test_2_pred = 'is11_test_result_nn.csv'\n",
    "\n",
    "dev_3_pred = 'egemaps_dev_result_svm.csv'\n",
    "test_3_pred = 'egemaps_test_result_svm.csv'\n",
    "\n",
    "# Load the predictions by speaker obtained with get_predictions_by_speaker.py\n",
    "preds_devel_1 = pd.read_csv(dev_1_pred)\n",
    "preds_devel_1.columns=['file_id', 'predictions_1']\n",
    "preds_test_1 = pd.read_csv(test_1_pred)\n",
    "preds_test_1.columns=['file_id', 'predictions_1']\n",
    "\n",
    "preds_devel_2 = pd.read_csv(dev_2_pred)\n",
    "preds_devel_2.columns=['file_id', 'predictions_2']\n",
    "preds_test_2 = pd.read_csv(test_2_pred)\n",
    "preds_test_2.columns=['file_id', 'predictions_2']\n",
    "\n",
    "preds_devel_3 = pd.read_csv(dev_3_pred)\n",
    "preds_devel_3.columns=['file_id', 'predictions_3']\n",
    "preds_test_3 = pd.read_csv(test_3_pred)\n",
    "preds_test_3.columns=['file_id', 'predictions_3']\n",
    "\n",
    "\n",
    "# Merge all predictions and labels (if available) as columns of the same dataframe:\n",
    "devel = pd.merge(pd.merge(pd.merge(labels_devel, preds_devel_1, on='file_id'), preds_devel_2, on='file_id'), preds_devel_3, on=\"file_id\")\n",
    "test = pd.merge(pd.merge(preds_test_1, preds_test_2, on='file_id'),  preds_test_3, on=\"file_id\")\n",
    "\n",
    "n_predictors = 3\n",
    "\n",
    "# TODO: compute the majority vote\n",
    "devel['mv'] = devel[devel.columns[-n_predictors:]].sum(axis=1)/n_predictors > 0.5\n",
    "devel[\"mv\"] = devel[\"mv\"].astype(int)\n",
    "test['mv'] = test[test.columns[-n_predictors:]].sum(axis=1)/n_predictors > 0.5\n",
    "test[\"mv\"] = test[\"mv\"].astype(int)\n",
    "\n",
    "devel.to_csv(\"dev_result_fusion.csv\", index=False)\n",
    "test.to_csv(\"test.result.fusion.csv\", index=False)\n",
    "\n",
    "# Print out the results for each model and for the final combination\n",
    "print(\"Results for the Development Dataset\")\n",
    "\n",
    "print(\"Results for prediction 1\")\n",
    "f1 = precision_recall_fscore_support(devel.label.values, devel.predictions_1.values, labels=[0,1], average='macro')\n",
    "print(f1)\n",
    "\n",
    "print(\"Results for tprediction 2\")\n",
    "f1 = precision_recall_fscore_support(devel.label.values, devel.predictions_2.values, labels=[0,1], average='macro')\n",
    "print(f1)\n",
    "\n",
    "print(\"Results for tprediction 3\")\n",
    "f1 = precision_recall_fscore_support(devel.label.values, devel.predictions_3.values, labels=[0,1], average='macro')\n",
    "print(f1)\n",
    "\n",
    "print(\"Results for majority vote\")\n",
    "f1 = precision_recall_fscore_support(devel.label.values, devel.mv.values, labels=[0,1], average='macro')\n",
    "print(f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
